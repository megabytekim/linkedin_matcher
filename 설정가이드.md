# 📋 LinkedIn 채용공고 스크래퍼 설정 가이드

이 가이드는 LinkedIn 채용공고 스크래퍼를 처음부터 설정하는 방법을 단계별로 설명합니다.

## 📋 사전 준비사항

- **Python 3.8+** 설치
- **Git** 설치
- **Google 계정** (Gmail API 사용)
- **OpenAI 계정** (GPT-4 API 사용, 선택사항)

## 🚀 1단계: 프로젝트 설정

### 저장소 클론 및 환경 설정

```bash
# 저장소 클론
git clone [your-repository-url]
cd linkedin_matcher

# 가상환경 생성
python -m venv venv

# 가상환경 활성화
# macOS/Linux:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# 의존성 패키지 설치
pip install -r requirements.txt

# Playwright 브라우저 설치
playwright install
```

## 🔐 2단계: Gmail API 설정

### Google Cloud Console 설정

1. **Google Cloud Console 접속**
   - [Google Cloud Console](https://console.cloud.google.com/) 방문
   - Google 계정으로 로그인

2. **새 프로젝트 생성**
   ```
   프로젝트 선택 → 새 프로젝트 → 프로젝트 이름 입력 → 만들기
   ```

3. **Gmail API 활성화**
   ```
   API 및 서비스 → 라이브러리 → "Gmail API" 검색 → 사용 설정
   ```

4. **OAuth 동의 화면 구성**
   ```
   API 및 서비스 → OAuth 동의 화면 → 외부 → 만들기
   ```
   - **앱 이름**: LinkedIn Job Scraper
   - **사용자 지원 이메일**: 본인 이메일
   - **개발자 연락처 정보**: 본인 이메일
   - 저장 후 계속

5. **OAuth 클라이언트 ID 생성**
   ```
   API 및 서비스 → 사용자 인증 정보 → 사용자 인증 정보 만들기 → OAuth 클라이언트 ID
   ```
   - **애플리케이션 유형**: 데스크톱 애플리케이션
   - **이름**: LinkedIn Scraper Desktop
   - 만들기

6. **credentials.json 다운로드**
   - 생성된 클라이언트 ID 옆의 다운로드 버튼 클릭
   - `credentials.json` 파일을 프로젝트 루트 디렉토리에 저장

### Gmail 권한 설정

```bash
# 첫 Gmail 접근 테스트
python -c "
from gmail_module.gmail_api import GmailAPI
gmail = GmailAPI()
print('Gmail API 설정 완료!')
"
```

브라우저가 열리고 Google 로그인을 요청하면:
1. Gmail 계정으로 로그인
2. 앱 권한 승인
3. `token.json` 파일이 자동 생성됨

## 🤖 3단계: OpenAI API 설정 (선택사항)

### API 키 발급

1. **OpenAI 웹사이트 방문**
   - [OpenAI Platform](https://platform.openai.com/) 접속
   - 계정 생성 또는 로그인

2. **API 키 생성**
   ```
   Dashboard → API Keys → Create new secret key
   ```
   - 키 이름: LinkedIn Scraper
   - 생성된 키를 안전한 곳에 복사

### 환경 변수 설정

프로젝트 루트에 `.env` 파일 생성:

```env
# OpenAI API 키 (GPT-4 사용시 필요)
OPENAI_API_KEY=sk-your-openai-api-key-here

# Gmail 설정 (기본값 사용 가능)
GMAIL_CREDENTIALS_FILE=credentials.json
GMAIL_TOKEN_FILE=token.json
```

## 🧪 4단계: 설정 테스트

### 전체 시스템 테스트

```bash
# MCP 도구 종합 테스트
PYTHONPATH=. python test_mcp.py
```

**예상 결과:**
```
🧪 LinkedIn Job Scraper MCP Tests
============================================================
📧 Testing Gmail MCP Tools
==================================================
✅ Found 3 emails
✅ Found 0 job URLs
✅ Retrieved 2615 characters of content
✅ Label result: False

🌐 Testing LinkedIn Scraper MCP Tools
==================================================
✅ URL validation: True
✅ Guest URL: https://www.linkedin.com/jobs-guest/jobs/view/...
✅ Job summary: Senior Analyst... at Google
✅ Job scraping: Senior Analyst... at Google

🎯 Overall: 4/4 tests passed
🎉 All MCP tools are working!
```

### 개별 모듈 테스트

**Gmail 모듈 테스트:**
```bash
python -c "
from gmail_module.gmail_api import GmailAPI
gmail = GmailAPI()
emails = gmail.list_messages('from:linkedin.com', 3)
print(f'LinkedIn 이메일 {len(emails)}개 발견')
"
```

**스크래핑 모듈 테스트:**
```bash
python -c "
from scraper_module.job_scraper import JobScraper
scraper = JobScraper()
url = 'https://www.linkedin.com/jobs/view/4267369043'
result = scraper.validate_linkedin_url(url)
print(f'URL 검증 결과: {result}')
"
```

## 🚀 5단계: 실행 방법

### MCP 서버 모드 (AI 어시스턴트 연동)

```bash
# MCP 서버 시작
PYTHONPATH=. python core/serve.py
```

AI 어시스턴트(Claude Desktop 등)에서 `mcp_config.json` 설정:

```json
{
  "mcpServers": {
    "linkedin-scraper": {
      "command": "python",
      "args": ["-u", "core/serve.py"],
      "cwd": "/absolute/path/to/linkedin_matcher",
      "env": {"PYTHONPATH": "."}
    }
  }
}
```

### 로컬 호스트 모드 (대화형 챗봇)

```bash
# OpenAI 호스트 실행
python host/openai_host.py
```

대화 예시:
```
사용자: 최근 LinkedIn 이메일에서 개발자 채용공고를 찾아줘
AI: Gmail에서 LinkedIn 이메일을 검색하고 개발자 관련 채용공고를 스크래핑하겠습니다.
```

## 🔧 6단계: 고급 설정

### 검색 쿼리 커스터마이징

`config.py`에서 기본 Gmail 검색 쿼리 수정:

```python
# 최근 7일간 LinkedIn 이메일
DEFAULT_QUERY = "from:linkedin.com newer_than:7d"

# 특정 키워드 포함 이메일
DEFAULT_QUERY = "from:linkedin.com (developer OR engineer)"

# 읽지 않은 LinkedIn 이메일
DEFAULT_QUERY = "from:linkedin.com is:unread"
```

### 스크래핑 설정 조정

`scraper_module/job_scraper.py`에서 지연 시간 조정:

```python
class JobScraper:
    def __init__(self):
        self.min_delay = 2.0  # 최소 지연 (초)
        self.max_delay = 4.0  # 최대 지연 (초)
```

### 세션 메모리 설정

OpenAI 호스트의 메모리 관리 설정:

```python
# host/openai_host.py
MAX_CONVERSATION_HISTORY = 50    # 대화 기록 최대 개수
MAX_SESSION_MEMORY_SIZE = 1000   # 세션 메모리 최대 항목 수
```

## 🐛 7단계: 문제 해결

### 일반적인 문제들

**1. Gmail 인증 실패**
```bash
# 해결방법: 토큰 재생성
rm token.json
python -c "from gmail_module.gmail_api import GmailAPI; GmailAPI()"
```

**2. Playwright 브라우저 오류**
```bash
# 해결방법: 브라우저 재설치
playwright install --force
```

**3. OpenAI API 키 오류**
```bash
# 해결방법: API 키 확인
cat .env | grep OPENAI_API_KEY
```

**4. MCP 서버 연결 실패**
```bash
# 해결방법: 수동 서버 실행 테스트
PYTHONPATH=. python core/serve.py
```

### 로그 확인

**Gmail API 로그:**
```python
import logging
logging.getLogger('googleapiclient.discovery').setLevel(logging.DEBUG)
```

**스크래핑 로그:**
```python
# scraper_module/job_scraper.py 에서
self.debug_mode = True  # 상세 로그 출력
```

## 📊 8단계: 성능 최적화

### 동시 스크래핑 설정

여러 채용공고를 동시에 스크래핑하려면:

```python
# core/tools/scraper.py
async def scrape_multiple_jobs_parallel(urls, max_concurrent=3):
    """동시에 최대 3개까지 스크래핑"""
    semaphore = asyncio.Semaphore(max_concurrent)
    # ... 구현
```

### 캐싱 설정

중복 스크래핑 방지를 위한 캐시:

```python
# 24시간 캐시
JOB_CACHE_DURATION = 24 * 60 * 60  # 초
```

## ✅ 설정 완료 체크리스트

- [ ] Python 가상환경 생성 및 패키지 설치
- [ ] Google Cloud Console에서 Gmail API 활성화
- [ ] `credentials.json` 파일 다운로드 및 배치
- [ ] Gmail 첫 인증 완료 (`token.json` 생성 확인)
- [ ] OpenAI API 키 설정 (선택사항)
- [ ] `.env` 파일 생성 및 환경변수 설정
- [ ] Playwright 브라우저 설치
- [ ] `python test_mcp.py` 테스트 통과 (4/4)
- [ ] MCP 서버 정상 실행 확인
- [ ] AI 어시스턴트 또는 로컬 호스트 연동 테스트

## 🎯 다음 단계

설정이 완료되면:

1. **AI 어시스턴트 연동**: Claude Desktop, ChatGPT 등에서 MCP 도구 사용
2. **워크플로우 자동화**: 정기적인 채용공고 검색 및 알림 설정
3. **커스터마이징**: 특정 분야나 회사에 맞는 검색 쿼리 조정
4. **데이터 분석**: 수집된 채용공고 데이터 분석 및 시각화

**설정 완료! 이제 AI와 함께 효율적인 채용공고 검색을 시작하세요! 🚀** 