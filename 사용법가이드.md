# ğŸ¯ LinkedIn ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í¼ ì‚¬ìš©ë²• ê°€ì´ë“œ

ì´ ê°€ì´ë“œëŠ” LinkedIn ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í¼ì˜ ë‹¤ì–‘í•œ ì‚¬ìš© ë°©ë²•ê³¼ ì‹¤ì „ í™œìš©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ì‹œì‘í•˜ê¸°

### ì „ì²´ ì‹œìŠ¤í…œ í™•ì¸

ëª¨ë“  ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ ë¨¼ì € í™•ì¸í•˜ì„¸ìš”:

```bash
# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
PYTHONPATH=. python test_mcp.py
```

**âœ… 4/4 í…ŒìŠ¤íŠ¸ í†µê³¼**ê°€ ë‚˜ì™€ì•¼ ì •ìƒì…ë‹ˆë‹¤.

## ğŸ›ï¸ ë‘ ê°€ì§€ ì‚¬ìš© ëª¨ë“œ

### ğŸ¤– Mode 1: MCP ì„œë²„ ëª¨ë“œ (AI ì–´ì‹œìŠ¤í„´íŠ¸ ì—°ë™)

**ìµœê³ ì˜ AI ê²½í—˜ì„ ì›í•œë‹¤ë©´ ì´ ëª¨ë“œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤!**

#### ì„œë²„ ì‹œì‘

```bash
# MCP ì„œë²„ ì‹¤í–‰
PYTHONPATH=. python core/serve.py
```

#### AI ì–´ì‹œìŠ¤í„´íŠ¸ ì„¤ì •

Claude Desktop, ChatGPT ë“±ì—ì„œ MCP ì„¤ì •:

```json
{
  "mcpServers": {
    "linkedin-scraper": {
      "command": "python",
      "args": ["-u", "core/serve.py"],
      "cwd": "/Users/your-username/linkedin_matcher",
      "env": {"PYTHONPATH": "."}
    }
  }
}
```

#### ìì—°ì–´ ëŒ€í™” ì˜ˆì‹œ

```
ğŸ’¬ ì‚¬ìš©ì: "ìµœê·¼ ì¼ì£¼ì¼ê°„ ë°›ì€ LinkedIn ì´ë©”ì¼ì—ì„œ Python ê°œë°œì ì±„ìš©ê³µê³ ë¥¼ 
           ì°¾ì•„ì„œ ìŠ¤í¬ë˜í•‘í•´ì£¼ì„¸ìš”. ì›ê²©ê·¼ë¬´ ê°€ëŠ¥í•œ ê²ƒë“¤ ìœ„ì£¼ë¡œìš”."

ğŸ¤– AI: ë„¤, LinkedIn ì´ë©”ì¼ì„ ê²€ìƒ‰í•´ì„œ Python ê°œë°œì ì±„ìš©ê³µê³ ë¥¼ ì°¾ì•„ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

    1ï¸âƒ£ Gmailì—ì„œ ìµœê·¼ 7ì¼ê°„ LinkedIn ì´ë©”ì¼ ê²€ìƒ‰ì¤‘...
    âœ… 12ê°œì˜ LinkedIn ì´ë©”ì¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

    2ï¸âƒ£ ê° ì´ë©”ì¼ì—ì„œ ì±„ìš©ê³µê³  URL ì¶”ì¶œì¤‘...
    âœ… ì´ 8ê°œì˜ ì±„ìš©ê³µê³  ë§í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.

    3ï¸âƒ£ Python ê´€ë ¨ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘ì¤‘...
    
    ğŸ“‹ **ë°œê²¬í•œ Python ê°œë°œì ì±„ìš©ê³µê³  (3ê°œ)**

    ğŸ¯ **1. Senior Python Developer - ì¹´ì¹´ì˜¤**
    ğŸ’¼ ìœ„ì¹˜: ì„œìš¸, íŒêµ (ì›ê²©ê·¼ë¬´ ê°€ëŠ¥)
    ğŸ’° ì—°ë´‰: 6,000ë§Œì› - 8,500ë§Œì›
    ğŸ”— ì§€ì›: https://linkedin.com/jobs-guest/jobs/view/123...
    ğŸ“ "Python/Django ë°±ì—”ë“œ ê°œë°œ ê²½ë ¥ 5ë…„ ì´ìƒ, AWS í´ë¼ìš°ë“œ ê²½í—˜..."

    ğŸ¯ **2. Python Full-Stack Engineer - í† ìŠ¤**
    ğŸ’¼ ìœ„ì¹˜: ì„œìš¸, ê°•ë‚¨ (í•˜ì´ë¸Œë¦¬ë“œ ê·¼ë¬´)
    ğŸ’° ì—°ë´‰: 7,000ë§Œì› - 1ì–µì›
    ğŸ”— ì§€ì›: https://linkedin.com/jobs-guest/jobs/view/456...
    ğŸ“ "Python + React í’€ìŠ¤íƒ ê°œë°œì, í•€í…Œí¬ ì„œë¹„ìŠ¤ ê°œë°œ..."

    ì›í•˜ëŠ” ê³µê³ ê°€ ë” ìˆìœ¼ì‹ ê°€ìš”? íŠ¹ì • íšŒì‚¬ë‚˜ ì¡°ê±´ìœ¼ë¡œ ì¶”ê°€ ê²€ìƒ‰í•´ë“œë¦´ê¹Œìš”?
```

### ğŸ’» Mode 2: ë¡œì»¬ í˜¸ìŠ¤íŠ¸ ëª¨ë“œ (ì§ì ‘ ëŒ€í™”)

**OpenAI API í‚¤ê°€ ìˆë‹¤ë©´ ë¡œì»¬ì—ì„œ ì§ì ‘ ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**

#### í˜¸ìŠ¤íŠ¸ ì‹¤í–‰

```bash
# .env íŒŒì¼ì— OpenAI API í‚¤ ì„¤ì • í™•ì¸
cat .env

# OpenAI í˜¸ìŠ¤íŠ¸ ì‹¤í–‰
python host/openai_host.py
```

#### ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤

```
ğŸ¤– LinkedIn Job Scraper AI Assistant
ğŸ’¡ Gmailì—ì„œ ì±„ìš©ê³µê³ ë¥¼ ì°¾ê³  ìŠ¤í¬ë˜í•‘í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì> ìµœê·¼ êµ¬ê¸€ì—ì„œ ì˜¨ ì±„ìš©ê³µê³  ì´ë©”ì¼ ìˆì–´?

AI> Gmailì—ì„œ êµ¬ê¸€ ê´€ë ¨ ì±„ìš©ê³µê³ ë¥¼ ì°¾ì•„ë³´ê² ìŠµë‹ˆë‹¤.

    ğŸ” ê²€ìƒ‰ì¤‘: from:google.com OR from:linkedin.com 'google'
    
    âœ… êµ¬ê¸€ ê´€ë ¨ ì´ë©”ì¼ 2ê°œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤:
    
    1. Google - Senior Software Engineer (5ì¼ ì „)
    2. Google Cloud - DevOps Engineer (3ì¼ ì „)
    
    ì´ ì¤‘ì—ì„œ ì–´ë–¤ ê³µê³ ë¥¼ ìì„¸íˆ ìŠ¤í¬ë˜í•‘í•´ë“œë¦´ê¹Œìš”?

ì‚¬ìš©ì> ì²« ë²ˆì§¸ ê³µê³  ìì„¸íˆ ë³´ì—¬ì¤˜

AI> Senior Software Engineer ê³µê³ ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê² ìŠµë‹ˆë‹¤...
```

## ğŸ› ï¸ ì£¼ìš” ê¸°ëŠ¥ë³„ ì‚¬ìš©ë²•

### ğŸ“§ Gmail ì´ë©”ì¼ ê²€ìƒ‰

#### ê¸°ë³¸ ê²€ìƒ‰

```python
# Python ì½”ë“œë¡œ ì§ì ‘ ì‚¬ìš©
from core.tools.gmail import list_emails

# ìµœê·¼ LinkedIn ì´ë©”ì¼ 10ê°œ
emails = list_emails("from:linkedin.com", 10)

# íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨ ì´ë©”ì¼
emails = list_emails("from:linkedin.com (python OR django)", 5)

# ìµœê·¼ 7ì¼ê°„ ì´ë©”ì¼
emails = list_emails("from:linkedin.com newer_than:7d", 15)
```

#### ê³ ê¸‰ ê²€ìƒ‰ ì¿¼ë¦¬

```python
# íšŒì‚¬ë³„ ê²€ìƒ‰
emails = list_emails("from:linkedin.com (google OR kakao OR naver)", 10)

# ì§ë¬´ë³„ ê²€ìƒ‰  
emails = list_emails("from:linkedin.com (developer OR engineer OR scientist)", 20)

# ì½ì§€ ì•Šì€ ì´ë©”ì¼ë§Œ
emails = list_emails("from:linkedin.com is:unread", 5)

# íŠ¹ì • ê¸°ê°„ ì´ë©”ì¼
emails = list_emails("from:linkedin.com after:2025/1/1 before:2025/1/31", 50)
```

### ğŸ”— ì±„ìš©ê³µê³  URL ì¶”ì¶œ

```python
from core.tools.gmail import extract_job_urls

# ì´ë©”ì¼ì—ì„œ LinkedIn ì±„ìš©ê³µê³  URL ì¶”ì¶œ
email_id = "your-email-id-here"
urls = extract_job_urls(email_id)

print(f"ë°œê²¬í•œ ì±„ìš©ê³µê³ : {len(urls)}ê°œ")
for url_info in urls:
    print(f"- {url_info['link_text']}: {url_info['url']}")
```

### ğŸŒ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘

#### ë‹¨ì¼ ì±„ìš©ê³µê³  ìŠ¤í¬ë˜í•‘

```python
from core.tools.scraper import scrape_job

url = "https://www.linkedin.com/jobs/view/4267369043"
job_data = scrape_job(url, max_content_length=3000)

print(f"ì§ë¬´: {job_data['title']}")
print(f"íšŒì‚¬: {job_data['company']}")
print(f"ìœ„ì¹˜: {job_data['location']}")
print(f"ì„¤ëª…: {job_data['description'][:200]}...")
```

#### ì—¬ëŸ¬ ì±„ìš©ê³µê³  ì¼ê´„ ìŠ¤í¬ë˜í•‘

```python
from core.tools.scraper import scrape_multiple_jobs

urls = [
    "https://www.linkedin.com/jobs/view/123456789",
    "https://www.linkedin.com/jobs/view/987654321",
    "https://www.linkedin.com/jobs/view/456789123"
]

job_list = scrape_multiple_jobs(urls, max_content_length=2000)

for i, job in enumerate(job_list, 1):
    print(f"\n{i}. {job['title']} - {job['company']}")
    print(f"   ìœ„ì¹˜: {job['location']}")
    print(f"   URL: {job['url']}")
```

### ğŸ”„ ì™„ì „ ìë™í™” ì›Œí¬í”Œë¡œìš°

```python
# ì´ë©”ì¼ ê²€ìƒ‰ â†’ URL ì¶”ì¶œ â†’ ìŠ¤í¬ë˜í•‘ ìë™í™”
from core.tools.gmail import list_emails, extract_job_urls
from core.tools.scraper import scrape_job

def automated_job_search(query="from:linkedin.com", max_emails=5):
    """ì™„ì „ ìë™í™”ëœ ì±„ìš©ê³µê³  ê²€ìƒ‰"""
    
    # 1ë‹¨ê³„: ì´ë©”ì¼ ê²€ìƒ‰
    print(f"ğŸ” ì´ë©”ì¼ ê²€ìƒ‰: {query}")
    emails = list_emails(query, max_emails)
    
    all_jobs = []
    
    # 2ë‹¨ê³„: ê° ì´ë©”ì¼ì—ì„œ URL ì¶”ì¶œ ë° ìŠ¤í¬ë˜í•‘
    for email in emails:
        print(f"\nğŸ“§ ì²˜ë¦¬ì¤‘: {email['subject'][:50]}...")
        
        # URL ì¶”ì¶œ
        urls = extract_job_urls(email['id'])
        
        # ìŠ¤í¬ë˜í•‘
        for url_info in urls:
            print(f"   ğŸŒ ìŠ¤í¬ë˜í•‘: {url_info['url']}")
            job_data = scrape_job(url_info['url'])
            
            if job_data and 'error' not in job_data:
                job_data['email_subject'] = email['subject']
                job_data['email_date'] = email['date']
                all_jobs.append(job_data)
    
    return all_jobs

# ì‹¤í–‰
jobs = automated_job_search("from:linkedin.com (python OR django)", 3)
print(f"\nâœ… ì´ {len(jobs)}ê°œì˜ ì±„ìš©ê³µê³ ë¥¼ ìˆ˜ì§‘í–ˆìŠµë‹ˆë‹¤!")
```

## ğŸ¯ ì‹¤ì „ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### ğŸ” ì‹œë‚˜ë¦¬ì˜¤ 1: íŠ¹ì • ê¸°ìˆ  ìŠ¤íƒ ì±„ìš©ê³µê³  ì°¾ê¸°

**ëª©í‘œ**: React + Node.js ê°œë°œì ì±„ìš©ê³µê³  ì°¾ê¸°

**AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ìš”ì²­:**
```
"ìµœê·¼ 2ì£¼ê°„ ë°›ì€ LinkedIn ì´ë©”ì¼ì—ì„œ Reactì™€ Node.js ê°œë°œì 
ì±„ìš©ê³µê³ ë¥¼ ì°¾ì•„ì„œ ìŠ¤í¬ë˜í•‘í•´ì£¼ì„¸ìš”. 
ìŠ¤íƒ€íŠ¸ì—… ìœ„ì£¼ë¡œ ì°¾ì•„ì£¼ì‹œê³ , ì›ê²©ê·¼ë¬´ ê°€ëŠ¥í•œì§€ë„ í™•ì¸í•´ì£¼ì„¸ìš”."
```

**ì§ì ‘ ì½”ë“œë¡œ ì‹¤í–‰:**
```python
# React + Node.js ê´€ë ¨ ì´ë©”ì¼ ê²€ìƒ‰
emails = list_emails("from:linkedin.com (react OR nodejs OR 'node.js') newer_than:14d", 10)

for email in emails:
    urls = extract_job_urls(email['id'])
    for url_info in urls:
        job = scrape_job(url_info['url'])
        
        # ì›ê²©ê·¼ë¬´ í‚¤ì›Œë“œ ì²´í¬
        if job and any(keyword in job['description'].lower() 
                      for keyword in ['remote', 'ì›ê²©', 'flexible', 'ì¬íƒ']):
            print(f"ğŸ¯ ì›ê²©ê·¼ë¬´ ê°€ëŠ¥: {job['title']} - {job['company']}")
```

### ğŸ’° ì‹œë‚˜ë¦¬ì˜¤ 2: ì—°ë´‰ ì •ë³´ê°€ ìˆëŠ” ì±„ìš©ê³µê³  ì°¾ê¸°

**ëª©í‘œ**: ì—°ë´‰ ì •ë³´ê°€ ëª…ì‹œëœ ì‹œë‹ˆì–´ ê°œë°œì ì±„ìš©ê³µê³ 

**AI ì–´ì‹œìŠ¤í„´íŠ¸ì—ê²Œ ìš”ì²­:**
```
"ì‹œë‹ˆì–´ ê°œë°œì ì±„ìš©ê³µê³  ì¤‘ì—ì„œ ì—°ë´‰ ì •ë³´ê°€ ëª…ì‹œëœ ê²ƒë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”.
ì—°ë´‰ì´ ë†’ì€ ìˆœì„œë¡œ ì •ë ¬í•´ì„œ ë³´ì—¬ì£¼ì‹œê³ , 
ê° ê³µê³ ì˜ ì£¼ìš” ê¸°ìˆ  ìŠ¤íƒë„ ìš”ì•½í•´ì£¼ì„¸ìš”."
```

### ğŸ¢ ì‹œë‚˜ë¦¬ì˜¤ 3: íŠ¹ì • íšŒì‚¬ ì±„ìš©ê³µê³  ëª¨ë‹ˆí„°ë§

**ëª©í‘œ**: ê´€ì‹¬ ìˆëŠ” íšŒì‚¬ë“¤ì˜ ìƒˆë¡œìš´ ì±„ìš©ê³µê³  ì¶”ì 

```python
# ê´€ì‹¬ íšŒì‚¬ ëª©ë¡
target_companies = ["google", "apple", "microsoft", "amazon", "meta"]

for company in target_companies:
    query = f"from:linkedin.com {company} newer_than:3d"
    emails = list_emails(query, 5)
    
    if emails:
        print(f"\nğŸ¢ {company.upper()} ìƒˆë¡œìš´ ì±„ìš©ê³µê³ :")
        for email in emails:
            print(f"  ğŸ“§ {email['subject']}")
            # í•„ìš”ì‹œ ìŠ¤í¬ë˜í•‘ ì¶”ê°€
```

### ğŸ“Š ì‹œë‚˜ë¦¬ì˜¤ 4: ì±„ìš© ì‹œì¥ íŠ¸ë Œë“œ ë¶„ì„

**ëª©í‘œ**: ìµœê·¼ ì±„ìš©ê³µê³ ì—ì„œ ì¸ê¸° ê¸°ìˆ  ìŠ¤íƒ ë¶„ì„

```python
from collections import Counter

# ìµœê·¼ í•œ ë‹¬ê°„ ëª¨ë“  ì±„ìš©ê³µê³  ìˆ˜ì§‘
emails = list_emails("from:linkedin.com newer_than:30d", 50)

all_descriptions = []
for email in emails:
    urls = extract_job_urls(email['id'])
    for url_info in urls:
        job = scrape_job(url_info['url'])
        if job:
            all_descriptions.append(job['description'].lower())

# ê¸°ìˆ  ìŠ¤íƒ í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
tech_keywords = ['python', 'javascript', 'react', 'nodejs', 'java', 
                'kubernetes', 'docker', 'aws', 'machine learning', 'ai']

tech_counts = Counter()
for desc in all_descriptions:
    for tech in tech_keywords:
        if tech in desc:
            tech_counts[tech] += 1

print("ğŸ“Š ì¸ê¸° ê¸°ìˆ  ìŠ¤íƒ:")
for tech, count in tech_counts.most_common(10):
    print(f"  {tech}: {count}íšŒ ì–¸ê¸‰")
```

## ğŸ”§ ê³ ê¸‰ ì‚¬ìš©ë²•

### ğŸ“± ì•Œë¦¼ ì„¤ì •

ìƒˆë¡œìš´ ì±„ìš©ê³µê³ ê°€ ìˆì„ ë•Œ ì•Œë¦¼ì„ ë°›ë„ë¡ ì„¤ì •:

```python
import schedule
import time

def check_new_jobs():
    """ìƒˆë¡œìš´ ì±„ìš©ê³µê³  ì²´í¬"""
    emails = list_emails("from:linkedin.com is:unread", 5)
    
    if emails:
        print(f"ğŸ”” ìƒˆë¡œìš´ ì±„ìš©ê³µê³  {len(emails)}ê°œ ë°œê²¬!")
        # ì´ë©”ì¼ ì•Œë¦¼, ìŠ¬ë™ ë©”ì‹œì§€ ë“± ì¶”ê°€ ê°€ëŠ¥

# 30ë¶„ë§ˆë‹¤ ì²´í¬
schedule.every(30).minutes.do(check_new_jobs)

while True:
    schedule.run_pending()
    time.sleep(1)
```

### ğŸ’¾ ë°ì´í„° ì €ì¥

ìŠ¤í¬ë˜í•‘í•œ ì±„ìš©ê³µê³ ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥:

```python
import json
from datetime import datetime

def save_jobs_to_file(jobs, filename=None):
    """ì±„ìš©ê³µê³  ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    if not filename:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"jobs_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(jobs, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ {len(jobs)}ê°œ ì±„ìš©ê³µê³ ë¥¼ {filename}ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì‹œ
jobs = automated_job_search("from:linkedin.com python", 5)
save_jobs_to_file(jobs)
```

### ğŸ” ìŠ¤ë§ˆíŠ¸ í•„í„°ë§

AIë¥¼ ì´ìš©í•œ ì±„ìš©ê³µê³  í•„í„°ë§:

```python
def filter_jobs_by_criteria(jobs, criteria):
    """ì±„ìš©ê³µê³ ë¥¼ íŠ¹ì • ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§"""
    filtered = []
    
    for job in jobs:
        description = job['description'].lower()
        title = job['title'].lower()
        
        # ê¸°ìˆ  ìŠ¤íƒ í•„í„°
        if criteria.get('tech_stack'):
            required_tech = criteria['tech_stack']
            if any(tech.lower() in description for tech in required_tech):
                filtered.append(job)
        
        # ê²½ë ¥ ë ˆë²¨ í•„í„°
        if criteria.get('level'):
            level = criteria['level'].lower()
            if level in title or level in description:
                filtered.append(job)
    
    return filtered

# ì‚¬ìš© ì˜ˆì‹œ
jobs = automated_job_search("from:linkedin.com", 10)

criteria = {
    'tech_stack': ['Python', 'Django', 'PostgreSQL'],
    'level': 'senior'
}

filtered_jobs = filter_jobs_by_criteria(jobs, criteria)
print(f"ğŸ¯ í•„í„°ë§ ê²°ê³¼: {len(filtered_jobs)}ê°œ ì±„ìš©ê³µê³ ")
```

## ğŸš¨ ì£¼ì˜ì‚¬í•­ ë° ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤

### âš¡ ì„±ëŠ¥ ìµœì í™”

1. **ì ì ˆí•œ ì§€ì—° ì‹œê°„**: ë„ˆë¬´ ë¹ ë¥¸ ìš”ì²­ìœ¼ë¡œ ì°¨ë‹¨ë‹¹í•˜ì§€ ì•Šë„ë¡
2. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì±„ìš©ê³µê³ ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
3. **ìºì‹±**: ê°™ì€ URLì„ ì¤‘ë³µ ìŠ¤í¬ë˜í•‘í•˜ì§€ ì•Šë„ë¡

### ğŸ”’ ë³´ì•ˆ ë° ê°œì¸ì •ë³´

1. **API í‚¤ ë³´ì•ˆ**: `.env` íŒŒì¼ì„ Gitì— ì—…ë¡œë“œí•˜ì§€ ë§ ê²ƒ
2. **Gmail ê¶Œí•œ**: í•„ìš”í•œ ìµœì†Œ ê¶Œí•œë§Œ ìš”ì²­
3. **ë°ì´í„° ì €ì¥**: ë¯¼ê°í•œ ì •ë³´ëŠ” ì•”í˜¸í™”í•˜ì—¬ ì €ì¥

### ğŸ¤ LinkedIn ì´ìš©ì•½ê´€ ì¤€ìˆ˜

1. **ì ì ˆí•œ ê°„ê²©**: ê³¼ë„í•œ ìš”ì²­ ë°©ì§€
2. **ê°œì¸ ìš©ë„**: ìƒì—…ì  ëª©ì ìœ¼ë¡œ ëŒ€ëŸ‰ ìˆ˜ì§‘ ê¸ˆì§€
3. **ë¡œë´‡ ì°¨ë‹¨**: ì‚¬ëŒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ìš´ íŒ¨í„´ìœ¼ë¡œ ì ‘ê·¼

## ğŸ’¡ ë¬¸ì œ í•´ê²° íŒ

### ìì£¼ ë°œìƒí•˜ëŠ” ë¬¸ì œë“¤

**1. ìŠ¤í¬ë˜í•‘ì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš°**
```python
# ì¬ì‹œë„ ë¡œì§ ì¶”ê°€
import time

def scrape_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            result = scrape_job(url)
            if result and 'error' not in result:
                return result
        except Exception as e:
            print(f"ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")
            time.sleep(2)  # 2ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„
    
    return None
```

**2. ì´ë©”ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°**
```python
# ê²€ìƒ‰ ì¿¼ë¦¬ í™•ì¥
queries = [
    "from:linkedin.com",
    "from:noreply@linkedin.com", 
    "from:jobalerts@linkedin.com",
    "subject:job linkedin"
]

for query in queries:
    emails = list_emails(query, 5)
    if emails:
        print(f"âœ… ì¿¼ë¦¬ '{query}'ë¡œ {len(emails)}ê°œ ì´ë©”ì¼ ë°œê²¬")
        break
```

**3. MCP ì„œë²„ ì—°ê²° ë¬¸ì œ**
```bash
# ì„œë²„ ìˆ˜ë™ í…ŒìŠ¤íŠ¸
PYTHONPATH=. python -c "
from core.server_app import app
print('MCP ì„œë²„ ì •ìƒ ì‘ë™')
"
```

## ğŸ‰ ì„±ê³µì ì¸ ì‚¬ìš©ì„ ìœ„í•œ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] `test_mcp.py` í…ŒìŠ¤íŠ¸ í†µê³¼ (4/4)
- [ ] Gmailì—ì„œ LinkedIn ì´ë©”ì¼ ìµœì†Œ 1ê°œ ì´ìƒ ë°œê²¬
- [ ] ì‹¤ì œ LinkedIn URLë¡œ ìŠ¤í¬ë˜í•‘ í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] AI ì–´ì‹œìŠ¤í„´íŠ¸ ë˜ëŠ” ë¡œì»¬ í˜¸ìŠ¤íŠ¸ ì—°ë™ í™•ì¸
- [ ] ê°œì¸ì •ë³´ ë° ë³´ì•ˆ ì„¤ì • ì™„ë£Œ
- [ ] ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ ë˜ëŠ” ì•Œë¦¼ ì„¤ì • (ì„ íƒì‚¬í•­)

**ì´ì œ AIì™€ í•¨ê»˜ íš¨ìœ¨ì ì¸ ì±„ìš©ê³µê³  ê²€ìƒ‰ì„ ì‹œì‘í•˜ì„¸ìš”! ğŸš€**

ê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ GitHub Issuesì— ë¬¸ì˜í•´ì£¼ì„¸ìš”. ğŸ¤ 