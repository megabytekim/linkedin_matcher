# 🎯 LinkedIn 채용공고 스크래퍼 사용법 가이드

이 가이드는 LinkedIn 채용공고 스크래퍼의 다양한 사용 방법과 실전 활용법을 설명합니다.

## 🚀 시작하기

### 전체 시스템 확인

모든 설정이 완료되었는지 먼저 확인하세요:

```bash
# 가상환경 활성화
source venv/bin/activate

# 전체 시스템 테스트
PYTHONPATH=. python test_mcp.py
```

**✅ 4/4 테스트 통과**가 나와야 정상입니다.

## 🎛️ 두 가지 사용 모드

### 🤖 Mode 1: MCP 서버 모드 (AI 어시스턴트 연동)

**최고의 AI 경험을 원한다면 이 모드를 권장합니다!**

#### 서버 시작

```bash
# MCP 서버 실행
PYTHONPATH=. python core/serve.py
```

#### AI 어시스턴트 설정

Claude Desktop, ChatGPT 등에서 MCP 설정:

```json
{
  "mcpServers": {
    "linkedin-scraper": {
      "command": "python",
      "args": ["-u", "core/serve.py"],
      "cwd": "/Users/your-username/linkedin_matcher",
      "env": {"PYTHONPATH": "."}
    }
  }
}
```

#### 자연어 대화 예시

```
💬 사용자: "최근 일주일간 받은 LinkedIn 이메일에서 Python 개발자 채용공고를 
           찾아서 스크래핑해주세요. 원격근무 가능한 것들 위주로요."

🤖 AI: 네, LinkedIn 이메일을 검색해서 Python 개발자 채용공고를 찾아드리겠습니다.

    1️⃣ Gmail에서 최근 7일간 LinkedIn 이메일 검색중...
    ✅ 12개의 LinkedIn 이메일을 발견했습니다.

    2️⃣ 각 이메일에서 채용공고 URL 추출중...
    ✅ 총 8개의 채용공고 링크를 찾았습니다.

    3️⃣ Python 관련 채용공고 스크래핑중...
    
    📋 **발견한 Python 개발자 채용공고 (3개)**

    🎯 **1. Senior Python Developer - 카카오**
    💼 위치: 서울, 판교 (원격근무 가능)
    💰 연봉: 6,000만원 - 8,500만원
    🔗 지원: https://linkedin.com/jobs-guest/jobs/view/123...
    📝 "Python/Django 백엔드 개발 경력 5년 이상, AWS 클라우드 경험..."

    🎯 **2. Python Full-Stack Engineer - 토스**
    💼 위치: 서울, 강남 (하이브리드 근무)
    💰 연봉: 7,000만원 - 1억원
    🔗 지원: https://linkedin.com/jobs-guest/jobs/view/456...
    📝 "Python + React 풀스택 개발자, 핀테크 서비스 개발..."

    원하는 공고가 더 있으신가요? 특정 회사나 조건으로 추가 검색해드릴까요?
```

### 💻 Mode 2: 로컬 호스트 모드 (직접 대화)

**OpenAI API 키가 있다면 로컬에서 직접 대화할 수 있습니다.**

#### 호스트 실행

```bash
# .env 파일에 OpenAI API 키 설정 확인
cat .env

# OpenAI 호스트 실행
python host/openai_host.py
```

#### 대화형 인터페이스

```
🤖 LinkedIn Job Scraper AI Assistant
💡 Gmail에서 채용공고를 찾고 스크래핑하는 AI 어시스턴트입니다.

사용자> 최근 구글에서 온 채용공고 이메일 있어?

AI> Gmail에서 구글 관련 채용공고를 찾아보겠습니다.

    🔍 검색중: from:google.com OR from:linkedin.com 'google'
    
    ✅ 구글 관련 이메일 2개를 발견했습니다:
    
    1. Google - Senior Software Engineer (5일 전)
    2. Google Cloud - DevOps Engineer (3일 전)
    
    이 중에서 어떤 공고를 자세히 스크래핑해드릴까요?

사용자> 첫 번째 공고 자세히 보여줘

AI> Senior Software Engineer 공고를 스크래핑하겠습니다...
```

## 🛠️ 주요 기능별 사용법

### 📧 Gmail 이메일 검색

#### 기본 검색

```python
# Python 코드로 직접 사용
from core.tools.gmail import list_emails

# 최근 LinkedIn 이메일 10개
emails = list_emails("from:linkedin.com", 10)

# 특정 키워드 포함 이메일
emails = list_emails("from:linkedin.com (python OR django)", 5)

# 최근 7일간 이메일
emails = list_emails("from:linkedin.com newer_than:7d", 15)
```

#### 고급 검색 쿼리

```python
# 회사별 검색
emails = list_emails("from:linkedin.com (google OR kakao OR naver)", 10)

# 직무별 검색  
emails = list_emails("from:linkedin.com (developer OR engineer OR scientist)", 20)

# 읽지 않은 이메일만
emails = list_emails("from:linkedin.com is:unread", 5)

# 특정 기간 이메일
emails = list_emails("from:linkedin.com after:2025/1/1 before:2025/1/31", 50)
```

### 🔗 채용공고 URL 추출

```python
from core.tools.gmail import extract_job_urls

# 이메일에서 LinkedIn 채용공고 URL 추출
email_id = "your-email-id-here"
urls = extract_job_urls(email_id)

print(f"발견한 채용공고: {len(urls)}개")
for url_info in urls:
    print(f"- {url_info['link_text']}: {url_info['url']}")
```

### 🌐 채용공고 스크래핑

#### 단일 채용공고 스크래핑

```python
from core.tools.scraper import scrape_job

url = "https://www.linkedin.com/jobs/view/4267369043"
job_data = scrape_job(url, max_content_length=3000)

print(f"직무: {job_data['title']}")
print(f"회사: {job_data['company']}")
print(f"위치: {job_data['location']}")
print(f"설명: {job_data['description'][:200]}...")
```

#### 여러 채용공고 일괄 스크래핑

```python
from core.tools.scraper import scrape_multiple_jobs

urls = [
    "https://www.linkedin.com/jobs/view/123456789",
    "https://www.linkedin.com/jobs/view/987654321",
    "https://www.linkedin.com/jobs/view/456789123"
]

job_list = scrape_multiple_jobs(urls, max_content_length=2000)

for i, job in enumerate(job_list, 1):
    print(f"\n{i}. {job['title']} - {job['company']}")
    print(f"   위치: {job['location']}")
    print(f"   URL: {job['url']}")
```

### 🔄 완전 자동화 워크플로우

```python
# 이메일 검색 → URL 추출 → 스크래핑 자동화
from core.tools.gmail import list_emails, extract_job_urls
from core.tools.scraper import scrape_job

def automated_job_search(query="from:linkedin.com", max_emails=5):
    """완전 자동화된 채용공고 검색"""
    
    # 1단계: 이메일 검색
    print(f"🔍 이메일 검색: {query}")
    emails = list_emails(query, max_emails)
    
    all_jobs = []
    
    # 2단계: 각 이메일에서 URL 추출 및 스크래핑
    for email in emails:
        print(f"\n📧 처리중: {email['subject'][:50]}...")
        
        # URL 추출
        urls = extract_job_urls(email['id'])
        
        # 스크래핑
        for url_info in urls:
            print(f"   🌐 스크래핑: {url_info['url']}")
            job_data = scrape_job(url_info['url'])
            
            if job_data and 'error' not in job_data:
                job_data['email_subject'] = email['subject']
                job_data['email_date'] = email['date']
                all_jobs.append(job_data)
    
    return all_jobs

# 실행
jobs = automated_job_search("from:linkedin.com (python OR django)", 3)
print(f"\n✅ 총 {len(jobs)}개의 채용공고를 수집했습니다!")
```

## 🎯 실전 활용 시나리오

### 🔍 시나리오 1: 특정 기술 스택 채용공고 찾기

**목표**: React + Node.js 개발자 채용공고 찾기

**AI 어시스턴트에게 요청:**
```
"최근 2주간 받은 LinkedIn 이메일에서 React와 Node.js 개발자 
채용공고를 찾아서 스크래핑해주세요. 
스타트업 위주로 찾아주시고, 원격근무 가능한지도 확인해주세요."
```

**직접 코드로 실행:**
```python
# React + Node.js 관련 이메일 검색
emails = list_emails("from:linkedin.com (react OR nodejs OR 'node.js') newer_than:14d", 10)

for email in emails:
    urls = extract_job_urls(email['id'])
    for url_info in urls:
        job = scrape_job(url_info['url'])
        
        # 원격근무 키워드 체크
        if job and any(keyword in job['description'].lower() 
                      for keyword in ['remote', '원격', 'flexible', '재택']):
            print(f"🎯 원격근무 가능: {job['title']} - {job['company']}")
```

### 💰 시나리오 2: 연봉 정보가 있는 채용공고 찾기

**목표**: 연봉 정보가 명시된 시니어 개발자 채용공고

**AI 어시스턴트에게 요청:**
```
"시니어 개발자 채용공고 중에서 연봉 정보가 명시된 것들을 찾아주세요.
연봉이 높은 순서로 정렬해서 보여주시고, 
각 공고의 주요 기술 스택도 요약해주세요."
```

### 🏢 시나리오 3: 특정 회사 채용공고 모니터링

**목표**: 관심 있는 회사들의 새로운 채용공고 추적

```python
# 관심 회사 목록
target_companies = ["google", "apple", "microsoft", "amazon", "meta"]

for company in target_companies:
    query = f"from:linkedin.com {company} newer_than:3d"
    emails = list_emails(query, 5)
    
    if emails:
        print(f"\n🏢 {company.upper()} 새로운 채용공고:")
        for email in emails:
            print(f"  📧 {email['subject']}")
            # 필요시 스크래핑 추가
```

### 📊 시나리오 4: 채용 시장 트렌드 분석

**목표**: 최근 채용공고에서 인기 기술 스택 분석

```python
from collections import Counter

# 최근 한 달간 모든 채용공고 수집
emails = list_emails("from:linkedin.com newer_than:30d", 50)

all_descriptions = []
for email in emails:
    urls = extract_job_urls(email['id'])
    for url_info in urls:
        job = scrape_job(url_info['url'])
        if job:
            all_descriptions.append(job['description'].lower())

# 기술 스택 키워드 카운트
tech_keywords = ['python', 'javascript', 'react', 'nodejs', 'java', 
                'kubernetes', 'docker', 'aws', 'machine learning', 'ai']

tech_counts = Counter()
for desc in all_descriptions:
    for tech in tech_keywords:
        if tech in desc:
            tech_counts[tech] += 1

print("📊 인기 기술 스택:")
for tech, count in tech_counts.most_common(10):
    print(f"  {tech}: {count}회 언급")
```

## 🔧 고급 사용법

### 📱 알림 설정

새로운 채용공고가 있을 때 알림을 받도록 설정:

```python
import schedule
import time

def check_new_jobs():
    """새로운 채용공고 체크"""
    emails = list_emails("from:linkedin.com is:unread", 5)
    
    if emails:
        print(f"🔔 새로운 채용공고 {len(emails)}개 발견!")
        # 이메일 알림, 슬랙 메시지 등 추가 가능

# 30분마다 체크
schedule.every(30).minutes.do(check_new_jobs)

while True:
    schedule.run_pending()
    time.sleep(1)
```

### 💾 데이터 저장

스크래핑한 채용공고를 데이터베이스에 저장:

```python
import json
from datetime import datetime

def save_jobs_to_file(jobs, filename=None):
    """채용공고 데이터를 JSON 파일로 저장"""
    if not filename:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"jobs_{timestamp}.json"
    
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(jobs, f, ensure_ascii=False, indent=2)
    
    print(f"💾 {len(jobs)}개 채용공고를 {filename}에 저장했습니다.")

# 사용 예시
jobs = automated_job_search("from:linkedin.com python", 5)
save_jobs_to_file(jobs)
```

### 🔍 스마트 필터링

AI를 이용한 채용공고 필터링:

```python
def filter_jobs_by_criteria(jobs, criteria):
    """채용공고를 특정 기준으로 필터링"""
    filtered = []
    
    for job in jobs:
        description = job['description'].lower()
        title = job['title'].lower()
        
        # 기술 스택 필터
        if criteria.get('tech_stack'):
            required_tech = criteria['tech_stack']
            if any(tech.lower() in description for tech in required_tech):
                filtered.append(job)
        
        # 경력 레벨 필터
        if criteria.get('level'):
            level = criteria['level'].lower()
            if level in title or level in description:
                filtered.append(job)
    
    return filtered

# 사용 예시
jobs = automated_job_search("from:linkedin.com", 10)

criteria = {
    'tech_stack': ['Python', 'Django', 'PostgreSQL'],
    'level': 'senior'
}

filtered_jobs = filter_jobs_by_criteria(jobs, criteria)
print(f"🎯 필터링 결과: {len(filtered_jobs)}개 채용공고")
```

## 🚨 주의사항 및 베스트 프랙티스

### ⚡ 성능 최적화

1. **적절한 지연 시간**: 너무 빠른 요청으로 차단당하지 않도록
2. **배치 처리**: 여러 채용공고를 한 번에 처리
3. **캐싱**: 같은 URL을 중복 스크래핑하지 않도록

### 🔒 보안 및 개인정보

1. **API 키 보안**: `.env` 파일을 Git에 업로드하지 말 것
2. **Gmail 권한**: 필요한 최소 권한만 요청
3. **데이터 저장**: 민감한 정보는 암호화하여 저장

### 🤝 LinkedIn 이용약관 준수

1. **적절한 간격**: 과도한 요청 방지
2. **개인 용도**: 상업적 목적으로 대량 수집 금지
3. **로봇 차단**: 사람처럼 자연스러운 패턴으로 접근

## 💡 문제 해결 팁

### 자주 발생하는 문제들

**1. 스크래핑이 실패하는 경우**
```python
# 재시도 로직 추가
import time

def scrape_with_retry(url, max_retries=3):
    for attempt in range(max_retries):
        try:
            result = scrape_job(url)
            if result and 'error' not in result:
                return result
        except Exception as e:
            print(f"시도 {attempt + 1} 실패: {e}")
            time.sleep(2)  # 2초 대기 후 재시도
    
    return None
```

**2. 이메일을 찾을 수 없는 경우**
```python
# 검색 쿼리 확장
queries = [
    "from:linkedin.com",
    "from:noreply@linkedin.com", 
    "from:jobalerts@linkedin.com",
    "subject:job linkedin"
]

for query in queries:
    emails = list_emails(query, 5)
    if emails:
        print(f"✅ 쿼리 '{query}'로 {len(emails)}개 이메일 발견")
        break
```

**3. MCP 서버 연결 문제**
```bash
# 서버 수동 테스트
PYTHONPATH=. python -c "
from core.server_app import app
print('MCP 서버 정상 작동')
"
```

## 🎉 성공적인 사용을 위한 최종 체크리스트

- [ ] `test_mcp.py` 테스트 통과 (4/4)
- [ ] Gmail에서 LinkedIn 이메일 최소 1개 이상 발견
- [ ] 실제 LinkedIn URL로 스크래핑 테스트 성공
- [ ] AI 어시스턴트 또는 로컬 호스트 연동 확인
- [ ] 개인정보 및 보안 설정 완료
- [ ] 정기적인 모니터링 또는 알림 설정 (선택사항)

**이제 AI와 함께 효율적인 채용공고 검색을 시작하세요! 🚀**

궁금한 점이 있으시면 언제든지 GitHub Issues에 문의해주세요. 🤝 